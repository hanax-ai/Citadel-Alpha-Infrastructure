# HXP-Enterprise LLM Server - Task 1.5: Phi-3-Mini Model Deployment and Configuration

**Task Number:** 1.5  
**Task Title:** Phi-3-Mini Model Deployment and Configuration  
**Created:** 2025-01-18  
**Assigned To:** AI Model Team  
**Priority:** Medium  
**Estimated Duration:** 0.5 days  
**Phase:** Phase 1 - Core AI Model Services and Basic Infrastructure  
**Architecture Component:** AI Model Services - Efficiency-Optimized Model  
**Modular Library Module:** hxp_enterprise_llm.services.ai_models.phi_3_mini  

---

## üéØ **TASK DESCRIPTION**

### **Primary Objective:**
Deployment and configuration of the Phi-3-Mini model as the efficiency-optimized service on port 11403. This task implements the most resource-efficient AI model designed for high-volume, cost-effective inference operations.

### **Architecture Alignment:**
- **Component:** AI Model Services - Efficiency-Optimized Model (Section 4.4 of Architecture Document)
- **Integration Points:** vLLM inference engine, high-throughput processing, resource optimization
- **Performance Targets:** 500ms average latency, 2K context length, maximum throughput per resource unit
- **Resource Allocation:** 4GB memory, 2 CPU cores, efficiency optimization

### **Modular Library Integration:**
- **Primary Module:** hxp_enterprise_llm.services.ai_models.phi_3_mini
- **Supporting Modules:** hxp_enterprise_llm.services.core.vllm_engine, hxp_enterprise_llm.services.optimization.efficiency_manager
- **Configuration Schema:** Phi3MiniConfig
- **Testing Suite:** tests/unit/test_phi_3_mini.py
- **Orchestration Logic:** hxp_enterprise_llm.orchestration.efficiency_orchestrator

---

## ‚úÖ **SMART+ST VALIDATION**

| Principle | Status | Validation Notes | Architecture Alignment |
|-----------|--------|------------------|----------------------|
| **Specific** | ‚úÖ | Deploy Phi-3-Mini model with efficiency optimization | Aligns with efficiency-optimized architecture specifications |
| **Measurable** | ‚úÖ | 500ms latency, 2K context, 4GB memory usage | Architecture metrics validate completion |
| **Achievable** | ‚úÖ | Realistic given available resources and vLLM capabilities | Resource allocations support achievement |
| **Relevant** | ‚úÖ | Critical efficiency model for high-volume operations | Supports overall AI service architecture |
| **Small** | ‚úÖ | Focused on single model deployment with efficiency features | Appropriately scoped for efficiency-optimized component |
| **Testable** | ‚úÖ | Performance benchmarks, efficiency tests, throughput validation | Architecture validation criteria are testable |

---

## üîó **DEPENDENCIES AND PREREQUISITES**

### **Hard Dependencies (Must Complete 100%):**
- **Task Dependencies:** Task 1.1 (vLLM Service Framework and Systemd Configuration)
- **Architecture Dependencies:** vLLM 0.3.3, PyTorch, Transformers library
- **Infrastructure Dependencies:** 4GB available memory, 500GB storage space, 2 CPU cores
- **Modular Library Dependencies:** hxp_enterprise_llm.services.core.vllm_engine

### **Soft Dependencies (Should Complete):**
- **Recommended Tasks:** Task 0.3 (Storage Architecture), Task 0.4 (Network Configuration)
- **Performance Dependencies:** Base system performance baseline
- **Integration Dependencies:** Monitoring framework readiness

### **External Infrastructure Requirements:**
- **SQL Database Server (192.168.10.35):** Not required for this task
- **Vector Database Server (192.168.10.30):** Not required for this task
- **Metrics Server (192.168.10.37):** Not required for this task
- **Network Connectivity:** Internet access for model download, local network for service communication

---

## ‚öôÔ∏è **CONFIGURATION REQUIREMENTS**

### **Environment Variables (.env):**
```bash
# Phi-3-Mini Model Configuration
PHI_3_MINI_PORT=11403
PHI_3_MINI_MEMORY_GB=4
PHI_3_MINI_CPU_CORES=2
PHI_3_MINI_MODEL_PATH=/opt/models/microsoft-Phi-3-mini-4k-instruct
PHI_3_MINI_MODEL_NAME=microsoft/Phi-3-mini-4k-instruct

# vLLM Configuration for Phi-3-Mini
PHI_3_MINI_MAX_MODEL_LEN=2048
PHI_3_MINI_TENSOR_PARALLEL_SIZE=1
PHI_3_MINI_GPU_MEMORY_UTILIZATION=0.6
PHI_3_MINI_MAX_NUM_BATCHED_TOKENS=1024
PHI_3_MINI_MAX_NUM_SEQS=32

# Efficiency Configuration
PHI_3_MINI_EFFICIENCY_MODE=true
PHI_3_MINI_MAX_THROUGHPUT_RPS=100
PHI_3_MINI_MEMORY_OPTIMIZATION=true
PHI_3_MINI_CPU_OPTIMIZATION=true

# Performance Configuration
PHI_3_MINI_TARGET_LATENCY_MS=500
PHI_3_MINI_TARGET_THROUGHPUT_RPS=100
PHI_3_MINI_SWAP_SPACE=0
PHI_3_MINI_ENFORCE_EAGER=0

# Monitoring Configuration
PHI_3_MINI_METRICS_PORT=11404
PHI_3_MINI_HEALTH_CHECK_INTERVAL=10
```

### **Configuration Files:**
```yaml
# /opt/citadel/config/services/phi-3-mini.yaml
service:
  name: phi-3-mini
  port: 11403
  host: "0.0.0.0"
  workers: 1
  
model:
  path: /opt/models/microsoft-Phi-3-mini-4k-instruct
  name: microsoft/Phi-3-mini-4k-instruct
  max_model_len: 2048
  tensor_parallel_size: 1
  gpu_memory_utilization: 0.6
  max_num_batched_tokens: 1024
  max_num_seqs: 32
  
efficiency:
  efficiency_mode: true
  max_throughput_rps: 100
  memory_optimization: true
  cpu_optimization: true
  resource_monitoring: true
  
performance:
  target_latency_ms: 500
  target_throughput_rps: 100
  memory_limit_gb: 4
  cpu_cores: 2
  swap_space: 0
  enforce_eager: 0
  
monitoring:
  health_check_interval: 10
  metrics_collection_interval: 5
  prometheus_port: 11404
  log_level: INFO
```

### **Modular Library Configuration:**
```python
# Configuration schema from modular library
from hxp_enterprise_llm.services.ai_models.phi_3_mini.config import Phi3MiniConfig
from hxp_enterprise_llm.schemas.configuration.model_schemas import ModelConfigSchema

config = Phi3MiniConfig(
    port=11403,
    memory_gb=4,
    cpu_cores=2,
    model_path="/opt/models/microsoft-Phi-3-mini-4k-instruct",
    model_name="microsoft/Phi-3-mini-4k-instruct",
    max_model_len=2048,
    tensor_parallel_size=1,
    gpu_memory_utilization=0.6,
    max_num_batched_tokens=1024,
    max_num_seqs=32,
    efficiency_mode=True,
    max_throughput_rps=100,
    memory_optimization=True,
    cpu_optimization=True,
    target_latency_ms=500,
    target_throughput_rps=100,
    swap_space=0,
    enforce_eager=0
)
```

---

## üìù **DETAILED SUB-TASKS**

| Sub-Task | Description | Module/Component | Commands/Steps | Success Criteria | Duration |
|----------|-------------|------------------|----------------|------------------|----------|
| 1.5.1 | Download and verify Phi-3-Mini model | Model Management | Download model files and verify integrity | Model files downloaded and verified | 1h |
| 1.5.2 | Configure vLLM for efficiency optimization | vLLM Configuration | Optimize vLLM settings for lightweight processing | vLLM optimized for efficiency performance | 0.5h |
| 1.5.3 | Create systemd service configuration | Service Management | Create phi-3-mini service with resource limits | Service configuration operational | 0.25h |
| 1.5.4 | Implement efficiency optimization module | Modular Library | Implement efficiency management capabilities | Efficiency optimization operational | 1h |
| 1.5.5 | Implement model service module | Modular Library | Implement hxp_enterprise_llm.services.ai_models.phi_3_mini | Model service module operational | 1h |
| 1.5.6 | Configure monitoring and metrics | Monitoring | Set up Prometheus metrics and health checks | Monitoring operational with efficiency metrics | 0.5h |
| 1.5.7 | Efficiency and throughput testing | Testing | Test efficiency optimization and throughput performance | Efficiency and throughput validated | 0.75h |

### **Implementation Commands:**
```bash
# Environment setup
source /opt/citadel/env/bin/activate
cd /opt/citadel/hxp-enterprise-llm

# Model download and setup
mkdir -p /opt/models/microsoft-Phi-3-mini-4k-instruct
cd /opt/models/microsoft-Phi-3-mini-4k-instruct
huggingface-cli download microsoft/Phi-3-mini-4k-instruct --local-dir .

# Verify model files
ls -la /opt/models/microsoft-Phi-3-mini-4k-instruct/
sha256sum -c model.sha256

# Service configuration
sudo cp /opt/citadel/hxp-enterprise-llm/config/services/phi-3-mini.yaml /opt/citadel/config/services/
sudo systemctl daemon-reload

# Start service
sudo systemctl enable citadel-llm@phi-3-mini.service
sudo systemctl start citadel-llm@phi-3-mini.service

# Validation commands
systemctl status citadel-llm@phi-3-mini.service
curl -X GET http://192.168.10.29:11403/health
curl -X GET http://192.168.10.29:11404/metrics
```

---

## üéØ **SUCCESS CRITERIA AND VALIDATION**

### **Primary Objectives:**
- [ ] **Architecture Compliance:** Phi-3-Mini model operational with 4GB memory allocation
- [ ] **Performance Targets:** 500ms average latency, 2K context length support
- [ ] **Integration Validation:** Efficiency optimization operational, high throughput achieved
- [ ] **Monitoring Integration:** Efficiency-specific metrics and health checks active
- [ ] **Modular Library Integration:** Phi-3-Mini service module operational

### **Architecture Validation Commands:**
```bash
# Service health validation
curl -X GET http://192.168.10.29:11403/health
# Expected: {"status": "healthy", "model": "phi-3-mini", "context_length": 2048, "efficiency_mode": true, "timestamp": "..."}

# Performance validation
curl -X POST http://192.168.10.29:11403/v1/completions \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Quick test", "max_tokens": 50}'
# Expected: Response time < 500ms

# Efficiency validation
curl -X GET http://192.168.10.29:11403/efficiency
# Expected: Efficiency metrics and optimization status

# Throughput validation
ab -n 1000 -c 50 -T application/json -p efficiency_payload.json \
  http://192.168.10.29:11403/v1/completions
# Expected: Requests per second > 100
```

### **Performance Benchmarks:**
```bash
# Latency benchmark
for i in {1..50}; do
  time curl -X POST http://192.168.10.29:11403/v1/completions \
    -H "Content-Type: application/json" \
    -d '{"prompt": "Performance test", "max_tokens": 20}' > /dev/null
done
# Expected: Average response time < 500ms

# Throughput benchmark
ab -n 1000 -c 100 -T application/json -p efficiency_payload.json \
  http://192.168.10.29:11403/v1/completions
# Expected: Requests per second > 100

# Memory usage validation
systemctl show citadel-llm@phi-3-mini.service --property=MemoryCurrent
# Expected: Memory usage < 4GB

# CPU usage validation
systemctl show citadel-llm@phi-3-mini.service --property=CPUUsageNSec
# Expected: CPU usage within 2-core allocation
```

### **Integration Testing:**
```bash
# Model loading validation
python -c "
from hxp_enterprise_llm.services.ai_models.phi_3_mini.service import Phi3MiniService
service = Phi3MiniService(config)
print(service.get_model_info())
"
# Expected: Model loaded successfully with efficiency capabilities

# Efficiency optimization validation
python -c "
from hxp_enterprise_llm.services.optimization.efficiency_manager import EfficiencyManager
efficiency_mgr = EfficiencyManager()
print(efficiency_mgr.get_optimization_status())
"
# Expected: Efficiency optimizations active and operational
```

---

## üìä **MONITORING AND METRICS**

### **Model-Specific Metrics:**
- Model loading time (target: < 30 seconds)
- Inference latency (target: < 500ms average)
- Throughput per resource unit
- Memory efficiency ratio
- CPU utilization efficiency
- Error rate and failure patterns

### **Monitoring Integration:**
```bash
# Prometheus metrics endpoint
curl -X GET http://192.168.10.29:11404/metrics | grep phi
# Expected: Phi-3-Mini-specific metrics available

# Health check endpoint
curl -X GET http://192.168.10.29:11403/health
# Expected: Model healthy with efficiency metrics

# Efficiency metrics endpoint
curl -X GET http://192.168.10.29:11403/metrics/efficiency
# Expected: Efficiency optimization metrics
```

---

## üîß **TROUBLESHOOTING AND MAINTENANCE**

### **Common Issues:**
1. **Model loading fails:** Check available memory and storage space
2. **High latency:** Optimize vLLM configuration and resource allocation
3. **Low throughput:** Verify efficiency optimization settings
4. **Resource inefficiency:** Check optimization module configuration

### **Maintenance Procedures:**
- Daily: Check model performance and efficiency metrics
- Weekly: Review efficiency logs and optimization patterns
- Monthly: Update model files and efficiency algorithms
- Quarterly: Performance optimization and efficiency tuning

---

## üìö **DOCUMENTATION AND REFERENCES**

### **Related Documents:**
- HXP-Enterprise LLM Server Architecture Document (Section 4.4)
- Phi-3-Mini Model Documentation
- Efficiency Optimization Best Practices

### **Configuration References:**
- Model files: /opt/models/microsoft-Phi-3-mini-4k-instruct/
- Service config: /opt/citadel/config/services/phi-3-mini.yaml
- Log files: /var/log/citadel-llm/phi-3-mini/
- Metrics endpoint: http://192.168.10.29:11404/metrics 