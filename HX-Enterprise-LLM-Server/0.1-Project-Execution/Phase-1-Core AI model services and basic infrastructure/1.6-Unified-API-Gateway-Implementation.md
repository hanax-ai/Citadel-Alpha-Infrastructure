# HXP-Enterprise LLM Server - Task 1.6: Unified API Gateway Implementation

**Task Number:** 1.6  
**Task Title:** Unified API Gateway Implementation  
**Created:** 2025-01-18  
**Assigned To:** API Development Team  
**Priority:** Critical  
**Estimated Duration:** 2 days  
**Phase:** Phase 1 - Core AI Model Services and Basic Infrastructure  
**Architecture Component:** API Gateway and Load Balancing  
**Modular Library Module:** hxp_enterprise_llm.services.gateway.unified_api_gateway  

---

## ðŸŽ¯ **TASK DESCRIPTION**

### **Primary Objective:**
Implementation of the unified API gateway providing centralized access to all AI models with load balancing, health monitoring, and request routing capabilities. This task creates the primary interface for external applications and implements intelligent request distribution across the four AI models.

### **Architecture Alignment:**
- **Component:** API Gateway and Load Balancing (Section 5.1 of Architecture Document)
- **Integration Points:** All four AI model services, monitoring system, external applications
- **Performance Targets:** Intelligent routing, health monitoring, circuit breaker patterns
- **Resource Allocation:** 2GB memory, 4 CPU cores, high availability configuration

### **Modular Library Integration:**
- **Primary Module:** hxp_enterprise_llm.services.gateway.unified_api_gateway
- **Supporting Modules:** hxp_enterprise_llm.services.load_balancer, hxp_enterprise_llm.monitoring.health, hxp_enterprise_llm.services.circuit_breaker
- **Configuration Schema:** UnifiedAPIGatewayConfig
- **Testing Suite:** tests/unit/test_unified_api_gateway.py
- **Orchestration Logic:** hxp_enterprise_llm.orchestration.gateway_orchestrator

---

## âœ… **SMART+ST VALIDATION**

| Principle | Status | Validation Notes | Architecture Alignment |
|-----------|--------|------------------|----------------------|
| **Specific** | âœ… | Implement unified API gateway with load balancing and routing | Aligns with API gateway architecture specifications |
| **Measurable** | âœ… | All 4 models accessible, health monitoring operational, routing functional | Architecture metrics validate completion |
| **Achievable** | âœ… | Realistic given FastAPI capabilities and available resources | Resource allocations support achievement |
| **Relevant** | âœ… | Critical gateway for all external AI model access | Supports overall API architecture |
| **Small** | âœ… | Focused on gateway implementation with routing logic | Appropriately scoped for API gateway component |
| **Testable** | âœ… | Routing tests, health checks, load balancing validation | Architecture validation criteria are testable |

---

## ðŸ”— **DEPENDENCIES AND PREREQUISITES**

### **Hard Dependencies (Must Complete 100%):**
- **Task Dependencies:** Tasks 1.2, 1.3, 1.4, 1.5 (All AI Model Services)
- **Architecture Dependencies:** FastAPI, Uvicorn, all four AI model services operational
- **Infrastructure Dependencies:** 2GB available memory, 4 CPU cores, network connectivity
- **Modular Library Dependencies:** hxp_enterprise_llm.services.core.fastapi_app

### **Soft Dependencies (Should Complete):**
- **Recommended Tasks:** Task 0.3 (Storage Architecture), Task 0.4 (Network Configuration)
- **Performance Dependencies:** All AI model services performance baseline
- **Integration Dependencies:** Monitoring framework readiness

### **External Infrastructure Requirements:**
- **SQL Database Server (192.168.10.35):** Not required for this task
- **Vector Database Server (192.168.10.30):** Not required for this task
- **Metrics Server (192.168.10.37):** Not required for this task
- **Network Connectivity:** All AI model services accessible, external client access

---

## âš™ï¸ **CONFIGURATION REQUIREMENTS**

### **Environment Variables (.env):**
```bash
# Unified API Gateway Configuration
API_GATEWAY_PORT=8000
API_GATEWAY_HOST=0.0.0.0
API_GATEWAY_WORKERS=4
API_GATEWAY_MEMORY_GB=2
API_GATEWAY_CPU_CORES=4

# AI Model Service Endpoints
MIXTRAL_8X7B_ENDPOINT=http://192.168.10.29:11400
HERMES_2_ENDPOINT=http://192.168.10.29:11401
OPENCHAT_3_5_ENDPOINT=http://192.168.10.29:11402
PHI_3_MINI_ENDPOINT=http://192.168.10.29:11403

# Load Balancing Configuration
LOAD_BALANCER_ALGORITHM=round_robin
HEALTH_CHECK_INTERVAL=30
CIRCUIT_BREAKER_THRESHOLD=5
CIRCUIT_BREAKER_TIMEOUT=60

# Routing Configuration
DEFAULT_MODEL=mixtral-8x7b
MODEL_ROUTING_ENABLED=true
INTELLIGENT_ROUTING=true
COST_OPTIMIZATION_ENABLED=true

# Performance Configuration
REQUEST_TIMEOUT_SECONDS=30
MAX_CONCURRENT_REQUESTS=100
RATE_LIMITING_ENABLED=true
RATE_LIMIT_RPS=50

# Monitoring Configuration
PROMETHEUS_PORT=9090
HEALTH_CHECK_ENDPOINT=/health
METRICS_ENDPOINT=/metrics
```

### **Configuration Files:**
```yaml
# /opt/citadel/config/services/unified-api-gateway.yaml
service:
  name: unified-api-gateway
  port: 8000
  host: "0.0.0.0"
  workers: 4
  
gateway:
  default_model: mixtral-8x7b
  model_routing_enabled: true
  intelligent_routing: true
  cost_optimization_enabled: true
  
load_balancer:
  algorithm: round_robin
  health_check_interval: 30
  circuit_breaker_threshold: 5
  circuit_breaker_timeout: 60
  
models:
  mixtral-8x7b:
    endpoint: http://192.168.10.29:11400
    weight: 1.0
    max_concurrent: 10
    cost_per_request: 0.1
    
  hermes-2:
    endpoint: http://192.168.10.29:11401
    weight: 0.8
    max_concurrent: 20
    cost_per_request: 0.05
    
  openchat-3.5:
    endpoint: http://192.168.10.29:11402
    weight: 0.6
    max_concurrent: 50
    cost_per_request: 0.02
    
  phi-3-mini:
    endpoint: http://192.168.10.29:11403
    weight: 0.4
    max_concurrent: 100
    cost_per_request: 0.01
  
performance:
  request_timeout_seconds: 30
  max_concurrent_requests: 100
  rate_limiting_enabled: true
  rate_limit_rps: 50
  memory_limit_gb: 2
  cpu_cores: 4
  
monitoring:
  prometheus_port: 9090
  health_check_endpoint: /health
  metrics_endpoint: /metrics
  log_level: INFO
```

### **Modular Library Configuration:**
```python
# Configuration schema from modular library
from hxp_enterprise_llm.services.gateway.unified_api_gateway.config import UnifiedAPIGatewayConfig
from hxp_enterprise_llm.schemas.configuration.gateway_schemas import GatewayConfigSchema

config = UnifiedAPIGatewayConfig(
    port=8000,
    host="0.0.0.0",
    workers=4,
    memory_gb=2,
    cpu_cores=4,
    default_model="mixtral-8x7b",
    model_routing_enabled=True,
    intelligent_routing=True,
    cost_optimization_enabled=True,
    load_balancer_algorithm="round_robin",
    health_check_interval=30,
    circuit_breaker_threshold=5,
    circuit_breaker_timeout=60,
    request_timeout_seconds=30,
    max_concurrent_requests=100,
    rate_limiting_enabled=True,
    rate_limit_rps=50
)
```

---

## ðŸ“ **DETAILED SUB-TASKS**

| Sub-Task | Description | Module/Component | Commands/Steps | Success Criteria | Duration |
|----------|-------------|------------------|----------------|------------------|----------|
| 1.6.1 | Create FastAPI application structure | FastAPI Setup | Create FastAPI app with middleware and routing | FastAPI application operational | 1h |
| 1.6.2 | Implement load balancer module | Load Balancing | Implement round-robin and intelligent routing | Load balancer operational with all models | 2h |
| 1.6.3 | Implement health monitoring system | Health Monitoring | Create health checks for all AI model services | Health monitoring operational | 1h |
| 1.6.4 | Implement circuit breaker pattern | Circuit Breaker | Create circuit breaker for fault tolerance | Circuit breaker operational | 1h |
| 1.6.5 | Implement OpenAI-compatible endpoints | API Endpoints | Create /v1/chat/completions and /v1/completions | OpenAI-compatible endpoints operational | 2h |
| 1.6.6 | Configure Prometheus metrics | Monitoring | Set up metrics collection and export | Prometheus metrics operational | 1h |
| 1.6.7 | Implement CORS and security | Security | Configure CORS and basic security measures | Security configuration operational | 0.5h |
| 1.6.8 | Integration testing and validation | Testing | Test all endpoints and routing logic | All tests pass with routing validation | 1.5h |

### **Implementation Commands:**
```bash
# Environment setup
source /opt/citadel/env/bin/activate
cd /opt/citadel/hxp-enterprise-llm

# Service configuration
sudo cp /opt/citadel/hxp-enterprise-llm/config/services/unified-api-gateway.yaml /opt/citadel/config/services/
sudo systemctl daemon-reload

# Start service
sudo systemctl enable citadel-llm@unified-api-gateway.service
sudo systemctl start citadel-llm@unified-api-gateway.service

# Validation commands
systemctl status citadel-llm@unified-api-gateway.service
curl -X GET http://192.168.10.29:8000/health
curl -X GET http://192.168.10.29:8000/metrics
curl -X GET http://192.168.10.29:8000/v1/models
```

---

## ðŸŽ¯ **SUCCESS CRITERIA AND VALIDATION**

### **Primary Objectives:**
- [ ] **Architecture Compliance:** Unified API gateway operational with all 4 AI models
- [ ] **Performance Targets:** Intelligent routing, health monitoring, circuit breaker operational
- [ ] **Integration Validation:** All AI model services accessible through gateway
- [ ] **Monitoring Integration:** Gateway metrics and health checks active
- [ ] **Modular Library Integration:** Unified API gateway module operational

### **Architecture Validation Commands:**
```bash
# Gateway health validation
curl -X GET http://192.168.10.29:8000/health
# Expected: {"status": "healthy", "gateway": "unified-api-gateway", "models": ["mixtral-8x7b", "hermes-2", "openchat-3.5", "phi-3-mini"], "timestamp": "..."}

# Model listing validation
curl -X GET http://192.168.10.29:8000/v1/models
# Expected: List of all 4 AI models with their capabilities

# Routing validation
curl -X POST http://192.168.10.29:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"messages": [{"role": "user", "content": "Test routing"}], "max_tokens": 50}'
# Expected: Response from appropriate model based on routing logic

# Load balancing validation
for i in {1..10}; do
  curl -X POST http://192.168.10.29:8000/v1/chat/completions \
    -H "Content-Type: application/json" \
    -d '{"messages": [{"role": "user", "content": "Load test $i"}], "max_tokens": 20}' &
done
wait
# Expected: Requests distributed across available models
```

### **Performance Benchmarks:**
```bash
# Gateway latency benchmark
for i in {1..20}; do
  time curl -X POST http://192.168.10.29:8000/v1/chat/completions \
    -H "Content-Type: application/json" \
    -d '{"messages": [{"role": "user", "content": "Gateway test"}], "max_tokens": 30}' > /dev/null
done
# Expected: Gateway overhead < 100ms

# Throughput benchmark
ab -n 200 -c 20 -T application/json -p gateway_payload.json \
  http://192.168.10.29:8000/v1/chat/completions
# Expected: Requests per second > 50

# Memory usage validation
systemctl show citadel-llm@unified-api-gateway.service --property=MemoryCurrent
# Expected: Memory usage < 2GB
```

### **Integration Testing:**
```bash
# Gateway service validation
python -c "
from hxp_enterprise_llm.services.gateway.unified_api_gateway.service import UnifiedAPIGatewayService
gateway = UnifiedAPIGatewayService(config)
print(gateway.get_health_status())
"
# Expected: Gateway healthy with all models accessible

# Load balancer validation
python -c "
from hxp_enterprise_llm.services.load_balancer import LoadBalancer
lb = LoadBalancer(config)
print(lb.get_available_models())
"
# Expected: All 4 models available and healthy
```

---

## ðŸ“Š **MONITORING AND METRICS**

### **Gateway-Specific Metrics:**
- Gateway response time (target: < 100ms overhead)
- Request routing distribution
- Model availability and health status
- Circuit breaker status and failures
- Rate limiting and throttling metrics
- Error rate and failure patterns

### **Monitoring Integration:**
```bash
# Prometheus metrics endpoint
curl -X GET http://192.168.10.29:8000/metrics | grep gateway
# Expected: Gateway-specific metrics available

# Health check endpoint
curl -X GET http://192.168.10.29:8000/health
# Expected: Gateway healthy with model status

# Model status endpoint
curl -X GET http://192.168.10.29:8000/models/status
# Expected: Status of all AI model services
```

---

## ðŸ”§ **TROUBLESHOOTING AND MAINTENANCE**

### **Common Issues:**
1. **Gateway startup fails:** Check AI model service availability
2. **Routing failures:** Verify model endpoints and health status
3. **High latency:** Check load balancer configuration and model performance
4. **Circuit breaker trips:** Investigate model service failures

### **Maintenance Procedures:**
- Daily: Check gateway health and model availability
- Weekly: Review routing patterns and performance metrics
- Monthly: Update gateway configuration and routing logic
- Quarterly: Performance optimization and load balancing tuning

---

## ðŸ“š **DOCUMENTATION AND REFERENCES**

### **Related Documents:**
- HXP-Enterprise LLM Server Architecture Document (Section 5.1)
- FastAPI Documentation
- Load Balancing Best Practices

### **Configuration References:**
- Gateway config: /opt/citadel/config/services/unified-api-gateway.yaml
- Log files: /var/log/citadel-llm/unified-api-gateway/
- Metrics endpoint: http://192.168.10.29:8000/metrics
- Health endpoint: http://192.168.10.29:8000/health 