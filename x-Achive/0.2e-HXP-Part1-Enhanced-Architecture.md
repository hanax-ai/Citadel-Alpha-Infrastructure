# Project 2: Vector Database Server Architecture Document
## Part 1: R&D Environment with Unified API Gateway Design

**Document ID:** ARCH-P02-VDB-P1-UNIFIED  
**Version:** 1.0  
**Date:** 2025-07-15  
**Server:** hx-vector-database-server (192.168.10.30)  
**Environment:** R&D with Minimum Security  
**Related Documents:** 
- Project2_Vector_Database_Server_PRD_Updated.md
- Project2_Vector_Database_Server_Part1_Enhanced_Implementation.md

---

## üéØ Executive Summary

This document defines the comprehensive architecture for the Citadel AI Operating System Vector Database Server, implementing a unified API Gateway design that consolidates REST, GraphQL, and gRPC interfaces while supporting both embedded AI model inference and external AI model integration patterns. The architecture addresses critical design decisions regarding embedding routing, metadata tracking, and bulk data operations across nine external AI models.

### **Key Architectural Decisions:**

1. **Unified API Gateway**: Single entry point for all vector operations across multiple protocols
2. **Hybrid Integration Pattern**: External AI models use both real-time routing and bulk write operations
3. **Embedded Model Priority**: Local models handle real-time embedding generation with metadata tracking
4. **Dual GPU Optimization**: Intelligent workload distribution across 12GB total VRAM
5. **Minimum Security R&D Focus**: Essential security without development blockers

---

## üèóÔ∏è System Architecture Overview

### **High-Level Architecture Components**

```mermaid
graph TB
    subgraph "External AI Models (9 Models)"
        EXT1[Mixtral-8x7B<br/>192.168.10.29:11400]
        EXT2[Nous Hermes 2<br/>192.168.10.29:11401]
        EXT3[Yi-34B<br/>192.168.10.28:11404]
        EXT4[OpenChat 3.5<br/>192.168.10.29:11402]
        EXT5[Phi-3 Mini<br/>192.168.10.29:11403]
        EXT6[DeepCoder-14B<br/>192.168.10.28:11405]
        EXT7[IMP Model<br/>192.168.10.28:11406]
        EXT8[DeepSeek<br/>192.168.10.28:11407]
        EXT9[General Purpose<br/>192.168.10.31:8000]
    end

    subgraph "Vector Database Server (192.168.10.30)"
        subgraph "API Gateway Layer"
            GATEWAY[Unified API Gateway<br/>Port 8000]
            GATEWAY --> REST[REST API<br/>Port 6333]
            GATEWAY --> GQL[GraphQL API<br/>Port 8080]
            GATEWAY --> GRPC[gRPC API<br/>Port 8081]
        end
        
        subgraph "Embedded AI Models (Local)"
            GPU0[GPU 0 - 6GB VRAM]
            GPU1[GPU 1 - 6GB VRAM]
            GPU0 --> MINILM[all-MiniLM-L6-v2<br/>384D]
            GPU0 --> PHI3[phi-3-mini<br/>3072D]
            GPU1 --> E5[e5-small<br/>384D]
            GPU1 --> BGE[bge-base<br/>768D]
        end
        
        subgraph "Vector Storage Layer"
            QDRANT[Qdrant Vector DB<br/>Port 6333/6334]
            COLLECTIONS[13 Vector Collections<br/>9 External + 4 Embedded]
        end
        
        subgraph "Metadata & Caching"
            REDIS[Redis Cache<br/>192.168.10.35:6379]
            POSTGRES[PostgreSQL Metadata<br/>192.168.10.35:5432]
        end
    end

    subgraph "External Services"
        METRICS[Metrics Server<br/>192.168.10.37]
        ORCHESTRATOR[Orchestration Server<br/>192.168.10.31]
    end

    %% Data Flow Connections
    EXT1 -.->|Bulk Write| GATEWAY
    EXT2 -.->|Real-time + Bulk| GATEWAY
    EXT3 -.->|Bulk Write| GATEWAY
    EXT4 -.->|Real-time + Bulk| GATEWAY
    EXT5 -.->|Real-time Routing| GATEWAY
    EXT6 -.->|Bulk Write| GATEWAY
    EXT7 -.->|Bulk Write| GATEWAY
    EXT8 -.->|Bulk Write| GATEWAY
    EXT9 -.->|Real-time Routing| GATEWAY

    GATEWAY --> QDRANT
    QDRANT --> COLLECTIONS
    GATEWAY --> REDIS
    GATEWAY --> POSTGRES
    
    ORCHESTRATOR <--> GATEWAY
    METRICS <-- GATEWAY
```

---

## üåê Unified API Gateway Architecture

### **API Gateway Design Principles**

The unified API Gateway serves as the single entry point for all vector database operations, providing protocol abstraction, request routing, and centralized monitoring.

#### **Gateway Components:**

```mermaid
graph LR
    subgraph "API Gateway (Port 8000)"
        subgraph "Protocol Handlers"
            REST_H[REST Handler]
            GQL_H[GraphQL Handler]
            GRPC_H[gRPC Handler]
        end
        
        subgraph "Core Services"
            AUTH[Authentication]
            ROUTE[Request Router]
            CACHE[Response Cache]
            MONITOR[Monitoring]
        end
        
        subgraph "Backend Connectors"
            QDRANT_CONN[Qdrant Connector]
            EMBED_CONN[Embedding Service]
            META_CONN[Metadata Service]
        end
    end

    CLIENT[Client Applications] --> REST_H
    CLIENT --> GQL_H
    CLIENT --> GRPC_H
    
    REST_H --> AUTH
    GQL_H --> AUTH
    GRPC_H --> AUTH
    
    AUTH --> ROUTE
    ROUTE --> CACHE
    CACHE --> QDRANT_CONN
    CACHE --> EMBED_CONN
    CACHE --> META_CONN
    
    ROUTE --> MONITOR
```

### **API Gateway Configuration**

```yaml
# /opt/citadel/config/api_gateway.yaml
api_gateway:
  host: "0.0.0.0"
  port: 8000
  
  protocols:
    rest:
      enabled: true
      path_prefix: "/api/v1"
      backend_port: 6333
    
    graphql:
      enabled: true
      path_prefix: "/graphql"
      backend_port: 8080
      playground: true  # R&D environment only
    
    grpc:
      enabled: true
      backend_port: 8081
      reflection: true  # R&D environment only
  
  authentication:
    type: "basic"  # Minimum security for R&D
    required: false  # Development mode
  
  routing:
    default_backend: "qdrant"
    load_balancing: "round_robin"
    timeout_ms: 30000
  
  caching:
    enabled: true
    backend: "redis"
    ttl_seconds: 300
    cache_embeddings: true
  
  monitoring:
    metrics_enabled: true
    logging_level: "INFO"
    export_port: 9090
```

---

## ü§ñ External AI Model Integration Patterns

### **Integration Strategy Decision Matrix**

The architecture implements a **hybrid integration pattern** where external AI models use different integration approaches based on their use cases and performance characteristics:

| Model | Server | Integration Pattern | Embedding Route | Metadata Tracking | Use Case |
|-------|--------|-------------------|-----------------|-------------------|----------|
| **Mixtral-8x7B** | 192.168.10.29:11400 | **Bulk Write Only** | Direct to Collections | Batch Metadata | General reasoning, large document processing |
| **Nous Hermes 2** | 192.168.10.29:11401 | **Real-time + Bulk** | Via Gateway | Full Tracking | RAG operations, document Q&A |
| **Yi-34B** | 192.168.10.28:11404 | **Bulk Write Only** | Direct to Collections | Batch Metadata | Long document analysis |
| **OpenChat 3.5** | 192.168.10.29:11402 | **Real-time + Bulk** | Via Gateway | Full Tracking | Conversational AI, tool integration |
| **Phi-3 Mini** | 192.168.10.29:11403 | **Real-time Routing** | Via Gateway | Full Tracking | Fast micro-operations |
| **DeepCoder-14B** | 192.168.10.28:11405 | **Bulk Write Only** | Direct to Collections | Batch Metadata | Code analysis, debugging |
| **IMP Model** | 192.168.10.28:11406 | **Bulk Write Only** | Direct to Collections | Batch Metadata | Specialized processing |
| **DeepSeek** | 192.168.10.28:11407 | **Bulk Write Only** | Direct to Collections | Batch Metadata | Research and analysis |
| **General Purpose** | 192.168.10.31:8000 | **Real-time Routing** | Via Gateway | Full Tracking | Orchestration, general tasks |

### **Integration Pattern Details**

#### **Pattern 1: Real-time Routing (3 Models)**
```mermaid
sequenceDiagram
    participant Client
    participant Gateway as API Gateway
    participant External as External AI Model
    participant Embed as Embedding Service
    participant Qdrant as Vector DB
    participant Meta as Metadata DB

    Client->>Gateway: Request with text
    Gateway->>External: Generate embedding
    External->>Gateway: Return embedding + metadata
    Gateway->>Embed: Enhance with local models
    Embed->>Gateway: Enhanced embedding
    Gateway->>Qdrant: Store vector
    Gateway->>Meta: Store metadata
    Gateway->>Client: Success response
```

**Models:** Phi-3 Mini, OpenChat 3.5, General Purpose  
**Characteristics:**
- Real-time embedding generation through Gateway
- Full metadata tracking and enhancement
- Local embedding model augmentation
- Immediate availability for search operations
- Higher latency but complete traceability

#### **Pattern 2: Hybrid Real-time + Bulk (2 Models)**
```mermaid
sequenceDiagram
    participant Client
    participant Gateway as API Gateway
    participant External as External AI Model
    participant Batch as Batch Processor
    participant Qdrant as Vector DB

    Note over Client,Qdrant: Real-time Path
    Client->>Gateway: Urgent request
    Gateway->>External: Generate embedding
    External->>Gateway: Return embedding
    Gateway->>Qdrant: Store immediately

    Note over Client,Qdrant: Bulk Path
    External->>Batch: Bulk embeddings
    Batch->>Qdrant: Batch insert
    Batch->>Gateway: Update metadata
```

**Models:** Nous Hermes 2, OpenChat 3.5  
**Characteristics:**
- Dual-mode operation for different use cases
- Real-time for urgent/interactive requests
- Bulk processing for large document sets
- Optimized for both latency and throughput
- Flexible routing based on request type

#### **Pattern 3: Bulk Write Only (4 Models)**
```mermaid
sequenceDiagram
    participant External as External AI Model
    participant Batch as Batch Processor
    participant Gateway as API Gateway
    participant Qdrant as Vector DB
    participant Meta as Metadata DB

    External->>Batch: Generate embeddings (bulk)
    Batch->>Gateway: Bulk write request
    Gateway->>Qdrant: Batch insert vectors
    Gateway->>Meta: Batch metadata
    Gateway->>Batch: Confirmation
    Batch->>External: Processing complete
```

**Models:** Mixtral-8x7B, Yi-34B, DeepCoder-14B, IMP, DeepSeek  
**Characteristics:**
- Optimized for high-throughput batch processing
- Minimal real-time interaction overhead
- Efficient for large-scale document processing
- Reduced metadata tracking (batch-level only)
- Maximum performance for bulk operations

---

## üèõÔ∏è Detailed Component Architecture

### **Vector Storage Layer Architecture**

```mermaid
graph TB
    subgraph "Vector Collections (13 Total)"
        subgraph "External Model Collections (9)"
            C1[mixtral_embeddings<br/>4096D, Cosine]
            C2[hermes_documents<br/>4096D, Cosine]
            C3[yi34_documents<br/>4096D, Cosine]
            C4[openchat_embeddings<br/>4096D, Cosine]
            C5[phi3_embeddings<br/>3072D, Cosine]
            C6[deepcoder_embeddings<br/>4096D, Cosine]
            C7[imp_embeddings<br/>4096D, Cosine]
            C8[deepseek_embeddings<br/>4096D, Cosine]
            C9[general_embeddings<br/>1536D, Cosine]
        end
        
        subgraph "Embedded Model Collections (4)"
            E1[minilm_general<br/>384D, Cosine]
            E2[phi3mini_embeddings<br/>3072D, Cosine]
            E3[e5small_embeddings<br/>384D, Cosine]
            E4[bgebase_embeddings<br/>768D, Cosine]
        end
    end

    subgraph "Storage Configuration"
        STORAGE[21.8TB Total Storage]
        NVME[3.6TB NVMe SSD<br/>Primary Performance]
        HDD[18.2TB HDD<br/>Bulk Storage]
    end

    subgraph "Performance Optimization"
        HNSW[HNSW Index<br/>m=16, ef_construct=200]
        SEGMENT[Segment Management<br/>100MB segments]
        CACHE[Memory Cache<br/>78GB RAM]
    end

    C1 --> STORAGE
    C2 --> STORAGE
    C3 --> STORAGE
    C4 --> STORAGE
    C5 --> STORAGE
    C6 --> STORAGE
    C7 --> STORAGE
    C8 --> STORAGE
    C9 --> STORAGE
    E1 --> STORAGE
    E2 --> STORAGE
    E3 --> STORAGE
    E4 --> STORAGE

    STORAGE --> NVME
    STORAGE --> HDD
    STORAGE --> HNSW
    STORAGE --> SEGMENT
    STORAGE --> CACHE
```

### **Embedded AI Models GPU Architecture**

```mermaid
graph TB
    subgraph "GPU Memory Management (12GB Total)"
        subgraph "GPU 0 - NVIDIA GT 1030 (6GB)"
            GPU0_MEM[6GB VRAM]
            MINILM_MODEL[all-MiniLM-L6-v2<br/>~500MB]
            PHI3_MODEL[phi-3-mini<br/>~2.5GB]
            GPU0_FREE[~3GB Free]
        end
        
        subgraph "GPU 1 - NVIDIA GT 1030 (6GB)"
            GPU1_MEM[6GB VRAM]
            E5_MODEL[e5-small<br/>~400MB]
            BGE_MODEL[bge-base<br/>~1.2GB]
            GPU1_FREE[~4.4GB Free]
        end
    end

    subgraph "Model Management"
        LOADER[Dynamic Model Loader]
        SCHEDULER[GPU Scheduler]
        MONITOR[Memory Monitor]
    end

    subgraph "Embedding API Service"
        FASTAPI[FastAPI Service<br/>Port 8000]
        ENDPOINTS[4 Model Endpoints]
        BATCH[Batch Processing]
    end

    GPU0_MEM --> MINILM_MODEL
    GPU0_MEM --> PHI3_MODEL
    GPU1_MEM --> E5_MODEL
    GPU1_MEM --> BGE_MODEL

    LOADER --> GPU0_MEM
    LOADER --> GPU1_MEM
    SCHEDULER --> LOADER
    MONITOR --> SCHEDULER

    FASTAPI --> ENDPOINTS
    ENDPOINTS --> BATCH
    BATCH --> SCHEDULER
```

---

## üîÑ Data Flow Architecture

### **Complete System Data Flow**

```mermaid
flowchart TD
    subgraph "Client Layer"
        WEB[Web Applications]
        API_CLIENTS[API Clients]
        MOBILE[Mobile Apps]
    end

    subgraph "API Gateway Layer (Port 8000)"
        GATEWAY[Unified API Gateway]
        AUTH[Authentication]
        ROUTER[Request Router]
        CACHE[Response Cache]
    end

    subgraph "Protocol Handlers"
        REST[REST API<br/>Port 6333]
        GRAPHQL[GraphQL API<br/>Port 8080]
        GRPC[gRPC API<br/>Port 8081]
    end

    subgraph "Processing Layer"
        EMBED_SVC[Embedding Service]
        BATCH_PROC[Batch Processor]
        META_SVC[Metadata Service]
    end

    subgraph "Storage Layer"
        QDRANT[Qdrant Vector DB]
        REDIS[Redis Cache<br/>192.168.10.35]
        POSTGRES[PostgreSQL<br/>192.168.10.35]
    end

    subgraph "External AI Models"
        REALTIME[Real-time Models<br/>3 Models]
        HYBRID[Hybrid Models<br/>2 Models]
        BULK[Bulk-only Models<br/>4 Models]
    end

    subgraph "Embedded Models"
        LOCAL_GPU[Local GPU Models<br/>4 Models]
    end

    %% Client connections
    WEB --> GATEWAY
    API_CLIENTS --> GATEWAY
    MOBILE --> GATEWAY

    %% Gateway routing
    GATEWAY --> AUTH
    AUTH --> ROUTER
    ROUTER --> CACHE

    %% Protocol distribution
    CACHE --> REST
    CACHE --> GRAPHQL
    CACHE --> GRPC

    %% Processing connections
    REST --> EMBED_SVC
    GRAPHQL --> EMBED_SVC
    GRPC --> EMBED_SVC

    EMBED_SVC --> LOCAL_GPU
    BATCH_PROC --> BULK
    META_SVC --> POSTGRES

    %% External model connections
    REALTIME --> GATEWAY
    HYBRID --> GATEWAY
    HYBRID --> BATCH_PROC
    BULK --> BATCH_PROC

    %% Storage connections
    EMBED_SVC --> QDRANT
    BATCH_PROC --> QDRANT
    CACHE --> REDIS
    META_SVC --> REDIS

    %% Data flow styling
    classDef client fill:#e1f5fe
    classDef gateway fill:#f3e5f5
    classDef protocol fill:#e8f5e8
    classDef processing fill:#fff3e0
    classDef storage fill:#fce4ec
    classDef external fill:#f1f8e9
    classDef embedded fill:#e0f2f1

    class WEB,API_CLIENTS,MOBILE client
    class GATEWAY,AUTH,ROUTER,CACHE gateway
    class REST,GRAPHQL,GRPC protocol
    class EMBED_SVC,BATCH_PROC,META_SVC processing
    class QDRANT,REDIS,POSTGRES storage
    class REALTIME,HYBRID,BULK external
    class LOCAL_GPU embedded
```

### **Embedding Generation Flow**

```mermaid
sequenceDiagram
    participant Client
    participant Gateway as API Gateway
    participant Router as Request Router
    participant Local as Local GPU Models
    participant External as External AI Models
    participant Qdrant as Vector DB
    participant Meta as Metadata DB

    Note over Client,Meta: Real-time Embedding Request
    Client->>Gateway: POST /embed {"text": "sample", "model": "auto"}
    Gateway->>Router: Route request
    
    alt Local Model Available
        Router->>Local: Generate embedding
        Local->>Router: Return 384D vector
    else External Model Required
        Router->>External: Generate embedding
        External->>Router: Return 4096D vector
    end
    
    Router->>Qdrant: Store vector + metadata
    Router->>Meta: Store tracking info
    Router->>Gateway: Success response
    Gateway->>Client: {"embedding_id": "123", "dimensions": 384}

    Note over Client,Meta: Bulk Processing Flow
    External->>Gateway: Bulk embeddings (1000 vectors)
    Gateway->>Router: Batch processing
    Router->>Qdrant: Batch insert
    Router->>Meta: Batch metadata
    Router->>Gateway: Batch confirmation
    Gateway->>External: Processing complete
```

---

## üõ°Ô∏è Security Architecture (Minimum R&D Configuration)

### **R&D Security Framework**

The architecture implements **minimum viable security** to avoid development blockers while maintaining essential protections:

```mermaid
graph TB
    subgraph "Network Security (Minimal)"
        UFW[UFW Firewall<br/>Essential Ports Only]
        INTERNAL[Internal Network<br/>192.168.10.0/24]
    end

    subgraph "API Security (Basic)"
        BASIC_AUTH[Basic Authentication<br/>Optional for R&D]
        RATE_LIMIT[Rate Limiting<br/>Development Friendly]
        CORS[CORS Enabled<br/>Permissive for R&D]
    end

    subgraph "Data Security (Essential)"
        ENCRYPT_TRANSIT[TLS for External<br/>Plain HTTP Internal]
        ACCESS_LOG[Access Logging<br/>Basic Monitoring]
        BACKUP_ENCRYPT[Backup Encryption<br/>AES-256]
    end

    subgraph "Operational Security"
        SERVICE_USER[agent0 Service User<br/>Non-root Execution]
        FILE_PERMS[File Permissions<br/>Restricted Access]
        LOG_ROTATION[Log Rotation<br/>Disk Space Management]
    end

    UFW --> INTERNAL
    BASIC_AUTH --> RATE_LIMIT
    RATE_LIMIT --> CORS
    ENCRYPT_TRANSIT --> ACCESS_LOG
    ACCESS_LOG --> BACKUP_ENCRYPT
    SERVICE_USER --> FILE_PERMS
    FILE_PERMS --> LOG_ROTATION
```

### **Security Configuration**

```yaml
# /opt/citadel/config/security.yaml
security:
  environment: "r&d"
  level: "minimum"
  
  network:
    firewall: "ufw"
    allowed_ports: [22, 6333, 6334, 8000, 8080, 8081]
    internal_only: true
  
  authentication:
    enabled: false  # R&D environment
    type: "basic"
    require_https: false  # Internal network
  
  authorization:
    rbac_enabled: false  # Simplified for R&D
    default_permissions: "read_write"
  
  encryption:
    at_rest: false  # R&D environment
    in_transit: false  # Internal network
    backups: true  # Essential protection
  
  monitoring:
    access_logs: true
    security_events: false  # Minimal overhead
    audit_trail: false  # R&D environment
```

---

## üìä Performance Architecture

### **Performance Optimization Strategy**

```mermaid
graph TB
    subgraph "CPU Optimization (Intel i9-9900K)"
        CORES[8 Cores, 16 Threads]
        AFFINITY[CPU Affinity<br/>Qdrant: Cores 0-3<br/>Embedding: Cores 4-7]
        SCALING[CPU Governor<br/>Performance Mode]
    end

    subgraph "Memory Optimization (78GB RAM)"
        QDRANT_MEM[Qdrant: 32GB]
        EMBED_MEM[Embedding Models: 16GB]
        CACHE_MEM[System Cache: 24GB]
        BUFFER_MEM[Buffer: 6GB]
    end

    subgraph "GPU Optimization (12GB VRAM)"
        GPU_SCHED[GPU Scheduler]
        MEM_POOL[Memory Pooling]
        BATCH_OPT[Batch Optimization]
    end

    subgraph "Storage Optimization (21.8TB)"
        NVME_HOT[NVMe: Hot Data<br/>Active Collections]
        HDD_COLD[HDD: Cold Data<br/>Archive Collections]
        IO_SCHED[I/O Scheduler<br/>Deadline for SSD]
    end

    subgraph "Network Optimization"
        TCP_TUNE[TCP Tuning<br/>High Throughput]
        CONN_POOL[Connection Pooling<br/>Persistent Connections]
        COMPRESS[Response Compression<br/>gzip Enabled]
    end

    CORES --> AFFINITY
    AFFINITY --> SCALING
    
    QDRANT_MEM --> EMBED_MEM
    EMBED_MEM --> CACHE_MEM
    CACHE_MEM --> BUFFER_MEM
    
    GPU_SCHED --> MEM_POOL
    MEM_POOL --> BATCH_OPT
    
    NVME_HOT --> HDD_COLD
    HDD_COLD --> IO_SCHED
    
    TCP_TUNE --> CONN_POOL
    CONN_POOL --> COMPRESS
```

### **Performance Targets**

| Metric | Target | Measurement Method |
|--------|--------|-------------------|
| **Vector Operations** | >10,000 ops/sec | Locust load testing |
| **Query Latency** | <10ms average | API response time monitoring |
| **Embedding Generation** | <100ms average | Local model inference timing |
| **GPU Utilization** | >80% efficiency | nvidia-smi monitoring |
| **Memory Utilization** | <90% peak usage | System memory monitoring |
| **Storage I/O** | >1GB/s throughput | iostat monitoring |
| **API Throughput** | >1000 req/sec | Gateway performance testing |
| **Concurrent Connections** | >500 connections | Connection pool monitoring |

---

## üîß Deployment Architecture

### **Service Deployment Topology**

```mermaid
graph TB
    subgraph "System Services"
        SYSTEMD[systemd Service Manager]
        QDRANT_SVC[qdrant.service]
        GATEWAY_SVC[citadel-gateway.service]
        EMBED_SVC[citadel-embedding.service]
        GRAPHQL_SVC[citadel-graphql.service]
        GRPC_SVC[citadel-grpc.service]
    end

    subgraph "Application Layer"
        PYTHON_ENV[Python 3.12.3 Virtual Environment<br/>/opt/citadel/env]
        CONFIG[Configuration Management<br/>/opt/citadel/config]
        SCRIPTS[Management Scripts<br/>/opt/citadel/scripts]
    end

    subgraph "Data Layer"
        MODELS[AI Models<br/>/opt/models]
        VECTOR_DATA[Vector Data<br/>/opt/qdrant/data]
        LOGS[Application Logs<br/>/var/log/citadel]
        BACKUPS[Backups<br/>/backup/qdrant]
    end

    subgraph "Monitoring Layer"
        HEALTH[Health Checks]
        METRICS[Metrics Collection]
        ALERTS[Basic Alerting]
    end

    SYSTEMD --> QDRANT_SVC
    SYSTEMD --> GATEWAY_SVC
    SYSTEMD --> EMBED_SVC
    SYSTEMD --> GRAPHQL_SVC
    SYSTEMD --> GRPC_SVC

    GATEWAY_SVC --> PYTHON_ENV
    EMBED_SVC --> PYTHON_ENV
    GRAPHQL_SVC --> PYTHON_ENV
    GRPC_SVC --> PYTHON_ENV

    PYTHON_ENV --> CONFIG
    CONFIG --> SCRIPTS

    QDRANT_SVC --> VECTOR_DATA
    EMBED_SVC --> MODELS
    GATEWAY_SVC --> LOGS
    SCRIPTS --> BACKUPS

    HEALTH --> METRICS
    METRICS --> ALERTS
```

### **Service Dependencies**

```mermaid
graph LR
    subgraph "Boot Sequence"
        SYSTEM[System Boot]
        NETWORK[Network Ready]
        STORAGE[Storage Mounted]
        QDRANT[Qdrant Service]
        EMBEDDING[Embedding Service]
        GATEWAY[API Gateway]
        PROTOCOLS[GraphQL/gRPC]
    end

    SYSTEM --> NETWORK
    NETWORK --> STORAGE
    STORAGE --> QDRANT
    QDRANT --> EMBEDDING
    EMBEDDING --> GATEWAY
    GATEWAY --> PROTOCOLS

    classDef critical fill:#ffcdd2
    classDef important fill:#fff3e0
    classDef optional fill:#e8f5e8

    class SYSTEM,NETWORK,STORAGE critical
    class QDRANT,EMBEDDING important
    class GATEWAY,PROTOCOLS optional
```

---

## üìà Monitoring and Observability Architecture

### **Monitoring Stack Integration**

```mermaid
graph TB
    subgraph "Vector Database Server (192.168.10.30)"
        subgraph "Metrics Collection"
            APP_METRICS[Application Metrics<br/>Prometheus Format]
            SYS_METRICS[System Metrics<br/>Node Exporter]
            GPU_METRICS[GPU Metrics<br/>nvidia-smi]
            CUSTOM_METRICS[Custom Metrics<br/>Vector Operations]
        end
        
        subgraph "Log Collection"
            APP_LOGS[Application Logs<br/>JSON Format]
            SYS_LOGS[System Logs<br/>journald]
            ACCESS_LOGS[Access Logs<br/>API Gateway]
        end
    end

    subgraph "Metrics Server (192.168.10.37)"
        PROMETHEUS[Prometheus<br/>Port 9090]
        GRAFANA[Grafana<br/>Port 3000]
        QDRANT_UI[Qdrant Web UI<br/>Port 8080]
        ALERTMANAGER[Alertmanager<br/>Port 9093]
    end

    APP_METRICS --> PROMETHEUS
    SYS_METRICS --> PROMETHEUS
    GPU_METRICS --> PROMETHEUS
    CUSTOM_METRICS --> PROMETHEUS

    APP_LOGS --> GRAFANA
    SYS_LOGS --> GRAFANA
    ACCESS_LOGS --> GRAFANA

    PROMETHEUS --> GRAFANA
    PROMETHEUS --> ALERTMANAGER
    GRAFANA --> QDRANT_UI
```

### **Key Monitoring Dashboards**

1. **Vector Database Performance**
   - Query latency percentiles
   - Operations per second
   - Collection sizes and growth
   - Index performance metrics

2. **GPU Utilization**
   - GPU memory usage per model
   - Inference throughput
   - Model switching frequency
   - Temperature and power consumption

3. **API Gateway Metrics**
   - Request rate by protocol (REST/GraphQL/gRPC)
   - Response time distribution
   - Error rates and status codes
   - Concurrent connection counts

4. **System Resources**
   - CPU utilization by core
   - Memory usage patterns
   - Storage I/O performance
   - Network throughput

---

## üöÄ Scalability and Future Architecture

### **Horizontal Scaling Preparation**

```mermaid
graph TB
    subgraph "Current Single-Node Architecture"
        CURRENT[Vector DB Server<br/>192.168.10.30]
    end

    subgraph "Future Multi-Node Architecture"
        subgraph "Load Balancer Layer"
            LB[Load Balancer<br/>HAProxy/Nginx]
        end
        
        subgraph "Vector Database Cluster"
            VDB1[Vector DB Node 1<br/>192.168.10.30]
            VDB2[Vector DB Node 2<br/>192.168.10.40]
            VDB3[Vector DB Node 3<br/>192.168.10.41]
        end
        
        subgraph "Shared Storage"
            SHARED_STORAGE[Distributed Storage<br/>GlusterFS/Ceph]
        end
    end

    subgraph "Migration Path"
        PHASE1[Phase 1: Single Node<br/>Current Implementation]
        PHASE2[Phase 2: Read Replicas<br/>Scale Read Operations]
        PHASE3[Phase 3: Sharding<br/>Distribute Collections]
        PHASE4[Phase 4: Full Cluster<br/>High Availability]
    end

    CURRENT --> PHASE1
    PHASE1 --> PHASE2
    PHASE2 --> PHASE3
    PHASE3 --> PHASE4

    LB --> VDB1
    LB --> VDB2
    LB --> VDB3

    VDB1 --> SHARED_STORAGE
    VDB2 --> SHARED_STORAGE
    VDB3 --> SHARED_STORAGE
```

---

## üìã Implementation Checklist

### **Architecture Validation Checklist**

- [ ] **API Gateway Design**
  - [ ] Unified entry point configured (Port 8000)
  - [ ] REST, GraphQL, gRPC protocols integrated
  - [ ] Request routing and load balancing implemented
  - [ ] Response caching configured

- [ ] **External Model Integration**
  - [ ] Real-time routing models identified (3 models)
  - [ ] Hybrid models configured (2 models)
  - [ ] Bulk-only models configured (4 models)
  - [ ] Metadata tracking patterns implemented

- [ ] **Embedded Model Architecture**
  - [ ] Dual GPU allocation optimized
  - [ ] Model loading and switching implemented
  - [ ] Performance monitoring configured
  - [ ] Memory management optimized

- [ ] **Vector Storage Design**
  - [ ] 13 collections created and configured
  - [ ] Storage optimization across 21.8TB
  - [ ] Performance tuning applied
  - [ ] Backup procedures implemented

- [ ] **Security Configuration**
  - [ ] Minimum security framework applied
  - [ ] R&D-friendly authentication configured
  - [ ] Network security (UFW) configured
  - [ ] Service user (agent0) configured

- [ ] **Monitoring Integration**
  - [ ] Metrics collection configured
  - [ ] Grafana dashboards prepared
  - [ ] Qdrant Web UI relocated to metrics server
  - [ ] Basic alerting configured

---

## üìö Conclusion

This architecture document defines a comprehensive, production-ready vector database server that serves as the semantic processing foundation for the Citadel AI Operating System. The unified API Gateway design provides flexibility and scalability, while the hybrid external model integration patterns optimize for both performance and functionality.

### **Key Architectural Strengths:**

1. **Unified Interface**: Single API Gateway for all vector operations
2. **Flexible Integration**: Hybrid patterns for external AI models
3. **GPU Optimization**: Intelligent dual-GPU utilization
4. **Scalable Design**: Foundation for future horizontal scaling
5. **R&D Optimized**: Minimum security with maximum development velocity

### **Next Steps:**

1. **Implementation**: Execute detailed tasks from implementation document
2. **Testing**: Comprehensive validation using pytest and Locust frameworks
3. **Integration**: Connect with external AI models and orchestration server
4. **Optimization**: Performance tuning based on real-world usage patterns
5. **Scaling**: Prepare for multi-node deployment as system grows

The architecture provides a solid foundation for the Citadel AI Operating System's vector processing capabilities while maintaining the flexibility needed for rapid R&D iteration and future production deployment.

---

**Document Status:** Complete architectural specification  
**Implementation Ready:** Yes, with detailed task breakdown available  
**Review Required:** Architecture review and approval before implementation  
**Dependencies:** Project 1 (SQL Database) completion required

